{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweets_Unsupervised_API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjapan87/TweetsUnsupervisedModel/blob/main/Tweets_Unsupervised_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZGGLxwpHgTH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "1255ecee-b803-46f5-ff5a-17995b781649"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Aug 29 20:19:39 2020\n",
        "\n",
        "@author: Dell\n",
        "\"\"\"\n",
        "import tweepy\n",
        "import re\n",
        "import pickle\n",
        "from tweepy import OAuthHandler\n",
        "\n",
        "#defining consumer key, consumer secret key, access token, & access secret key\n",
        "API_Key=\" \"\n",
        "API_Secret=\" \"\n",
        "Access_token=\" \"\n",
        "Access_token_secret=\" \"\n",
        "\n",
        "#this step is intializing tokens for clients authentication\n",
        "auth = OAuthHandler(API_Key,API_Secret) #authetication of application\n",
        "auth.set_access_token(Access_token,Access_token_secret) #user authentication\n",
        "\n",
        "#defining the string\n",
        "args=[\"japan\"];\n",
        "api_obj=tweepy.API(auth,timeout=10,wait_on_rate_limit=True)\n",
        "\n",
        "#save the tweets in a list\n",
        "List_Tweets=[]\n",
        "query=args[0]\n",
        "if len(args)==1:\n",
        "  for status in tweepy.Cursor(api_obj.search,q=query+\" -filter:retweets\",lang=\"en\",result_type=\"recent\").items(500):\n",
        "    List_Tweets.append(status.text)\n",
        "\n",
        "#Loading Pre-Trained model\n",
        "List_Tweets\n",
        "with open(\"classifier.pickle\",\"rb\") as PTmodel:\n",
        "    clf=pickle.load(PTmodel)\n",
        "    \n",
        "with open(\"tfidfmodel.pickle\",\"rb\") as TDmodel:\n",
        "    tdif=pickle.load(TDmodel)\n",
        "\n",
        "total_positive=0\n",
        "total_negative=0\n",
        "\n",
        "#pre-processing start\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "for tweets in List_Tweets:\n",
        "    tweets=re.sub(r'http\\S+',\" \",tweets)\n",
        "    tweets=re.sub(r'https\\S+',\" \",tweets)\n",
        "    tweets=re.sub(r'@\\S+',\"user\",tweets)\n",
        "    tweets=re.sub(\"[^a-zA-Z]\",\" \",tweets)\n",
        "    tweets=tweets.lower()\n",
        "    tweets=tweets.split()\n",
        "    stemming = PorterStemmer()\n",
        "    tweets = [stemming.stem(word) for word in tweets if not word in set(stopwords.words(\"english\"))]\n",
        "    tweets=\" \".join(tweets)\n",
        "    \n",
        "    sent = clf.predict(tdif.transform([tweets]).toarray())\n",
        "    #attaching\n",
        "    if sent[0] == 1:\n",
        "        total_positive += 1\n",
        "    #elif:\n",
        "     #   total_neutral\n",
        "    else:\n",
        "        total_negative += 1\n",
        "\n",
        "print(total_positive)\n",
        "print(total_negative)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "obj1 = [\"pstv\",\"ngtv\"] #category of bars is named from this sentence\n",
        "yAxis = np.arange(len(obj1))#order of the category\n",
        "plt.bar(yAxis,[total_positive,total_negative])\n",
        "plt.xticks(yAxis,obj1)\n",
        "plt.ylabel(\"number\")\n",
        "plt.title(\"positive & negative tweets\")\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.18.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.18.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.18.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}